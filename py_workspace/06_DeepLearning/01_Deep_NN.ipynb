{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch 에서의 Gradient Descent\n",
    "    우리는 이전 머신러닝 과정에서 선형회귀(Linear Regression)에 대해서 간단히 살펴보았다.\n",
    "    이번에는 파이토치를 이용해서 선형회귀를 위한 연산 그래프를 만들고 경사하강법을 이해하는 코드\n",
    "    를 다시 작성해 보자. 파이토치에서는 데이터의 기본단위로 텐서(Tensor)를 사용한다.\n",
    "    Numpy에서 np.array([1,2,3]) 과 동일한 것.\n",
    "    이러한 텐서를 연산의 기본 단위로 사용한다. 텐서를 생성하는 방법에는 torch.tensor() ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # pytorch는 그냥 torch로 불러온다\n",
    "import torchvision # 파이토치에서 vision은 Image Processing에 특화된 라이브러리\n",
    "import torch.nn as nn # nn은 Neural Net의 약자\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms # transforms... data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.2755e-39, 6.3368e-39, 9.2755e-39],\n",
       "        [9.2755e-39, 1.0653e-38, 1.0469e-38]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.Tensor(2,3) #2행 3열로 텐서를 만든다. 값은 랜덤하게 들어감.\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "tensor() 함수의 인자값으로 data.dtype, device, requires_grad 등이 있다.\n",
    "dtype - 데이터 값의 타입 지정\n",
    "device - 텐서를 어느 기기에 올릴 것인가를 지정...(CPU, GPU)\n",
    "requires_grad - 텐서의 기울기를 지정할지를 여부..(기본값은 False)... 미분 사용 여부 \n",
    "                => 이거 안 넣어주면 미분 못하고 Back Propagation 안 써서 학습이 안 됨\n",
    "                => Traing Model은 학습을 해야 하기 때문에 반드시 True로 설정해야 함.\n",
    "                => Test Model은 학습을 안 하므로 False로 해놓음. True로 해도 상관은 없는데 굳이 할 필요 없고 자원만 씀.\n",
    "'''\n",
    "x = torch.tensor(data=[2.0, 3.0], requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 9.], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x**2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11., 21.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 예측값 출력\n",
    "pred = 2*y + 3 # 2X^2 + 3\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.tensor([3.0, 4.0]) #라벨(정답)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss  tensor(25., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 2. loss 값을 구한다\n",
    "loss = torch.sum(torch.abs(pred-target)) # (11-3) + (21-4) = 25\n",
    "loss\n",
    "print('loss ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8., 12.]) None\n"
     ]
    }
   ],
   "source": [
    "# 3.가장 가파른 기울기로 하강하는 Weight를 찾는다.\n",
    "# = 가장 낮은 loss값을 구하는 Weight를 찾는다..... 미분, 편미분... Back Propagation\n",
    "loss.backward()\n",
    "\n",
    "'''\n",
    "x.grad ---> dy/dw = x (미분공식)\n",
    "w.grad ---> dy/dx = w\n",
    "'''\n",
    "print(x.grad, pred.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Type - tensor(), as_tensor()\n",
    "    Numpy 배열을 torch.Tensor 타입으로 변형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "int32\n",
      "<class 'numpy.ndarray'>\n",
      "****************************************\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "<class 'torch.Tensor'>\n",
      "****************************************\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Pytorch의 텐서 자료형은 Numpy의 array()와 동일한 것으로 이해...\n",
    "\n",
    "'''\n",
    "# 1. Numpy 배열을 torch.Tensor 타입으로 변형\n",
    "li = np.array([[1,2],[3,4]])\n",
    "print(li)\n",
    "print(li.dtype)\n",
    "print(type(li))\n",
    "\n",
    "print('*'*40)\n",
    "\n",
    "li_torch = torch.tensor(li)\n",
    "print(li_torch)\n",
    "print(type(li_torch))\n",
    "\n",
    "print('*'*40)\n",
    "\n",
    "li_as_torch = torch.as_tensor(li)\n",
    "print(li_as_torch)\n",
    "print(type(li_as_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# 2. 반대로 텐서를 Numpy 배열로 변형... torch.numpy()를 사용한다.\n",
    "li_tensor_numpy = li_as_torch.numpy()\n",
    "print(li_tensor_numpy)\n",
    "print(type(li_tensor_numpy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
